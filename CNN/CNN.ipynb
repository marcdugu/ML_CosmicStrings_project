{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages and \n",
    "\n",
    "import os\n",
    "import CNN \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN parameters\n",
    "num_files_load = 1000\n",
    "num_epochs = 50\n",
    "batch_size = int(num_files_load/100) #this we need to think about\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "\n",
    "#breakoff parameters\n",
    "min_validation_loss = float('inf') #initializing validation loss\n",
    "patience = 50\n",
    "min_delta = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Dataset\n",
    "root_dir = r'C:\\Users\\marcd\\Desktop\\Master\\Courses\\Machine_Learning\\Project\\data\\CostmiStrings\\mock_data' \n",
    "#root_dir = r'/Users/boribbens/Documents/Universiteit_Utrecht/EP_Master/Semester_1/Computational_aspects_of_Machine_Learning/ML_Project/Datafolder/mock_data'\n",
    "dataset = CNN.signal_dataset(root_dir=root_dir, num_files_load=num_files_load, normalized=True) # shape(10000,2,3,65536)-->(file, signal/label, telescope, time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Train/Test\n",
    "\n",
    "train_size = 0.7\n",
    "validation_size = 0.2\n",
    "test_size = 1 - (train_size + validation_size)\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 65536])\n",
      "Conv1: torch.Size([1, 16, 65532])\n",
      "Pool1: torch.Size([1, 16, 32766])\n",
      "Conv2: torch.Size([1, 32, 16382])\n",
      "Pool2: torch.Size([1, 32, 8191])\n",
      "Conv3: torch.Size([1, 64, 4095])\n",
      "Pool3: torch.Size([1, 64, 2047])\n",
      "Conv4: torch.Size([1, 128, 1023])\n",
      "Pool4: torch.Size([1, 128, 511])\n",
      "Conv5: torch.Size([1, 256, 255])\n",
      "Pool5: torch.Size([1, 256, 127])\n",
      "Conv6: torch.Size([1, 256, 64])\n",
      "Pool6: torch.Size([1, 256, 32])\n",
      "Flatten: torch.Size([1, 8192])\n"
     ]
    }
   ],
   "source": [
    "# Dummy CNN\n",
    "\n",
    "# Define the dummy CNN model\n",
    "dummy_model = CNN.DummyCNN()\n",
    "# Move the model to the appropriate device\n",
    "dummy_model = dummy_model.to(device)\n",
    "# Create a dummy input array (batch_size=1, channels=3, length=65536)\n",
    "dummy_input = torch.randn(1, 3, 65536).to(device)\n",
    "# Pass the dummy input through the model\n",
    "output = dummy_model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████████████████████████████████████████| 50/50 [05:28<00:00,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Run the NN:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m CNN\u001b[38;5;241m.\u001b[39mRunNeuralNetwork(train_loader, validation_loader, test_loader, learning_rate, weight_decay, num_epochs, patience, min_delta, Save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, HistName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHist\u001b[39m\u001b[38;5;124m'\u001b[39m, LearningName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marcd\\Desktop\\Git\\ML_course\\ML_CosmicStrings\\CNN\\CNN.py:287\u001b[0m, in \u001b[0;36mRunNeuralNetwork\u001b[1;34m(train_loader, validation_loader, test_loader, learning_rate, weight_decay, num_epochs, patience, min_delta, Save, HistName, LearningName)\u001b[0m\n\u001b[0;32m    284\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    285\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 287\u001b[0m     labels_array \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mnumpy()      \u001b[38;5;66;03m# Cannot convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     preds_array \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    290\u001b[0m countlist \u001b[38;5;241m=\u001b[39m Utils\u001b[38;5;241m.\u001b[39mhistogram_counting(labels_array, preds_array)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "#Run the NN:\n",
    "\n",
    "CNN.RunNeuralNetwork(train_loader, validation_loader, test_loader, learning_rate, weight_decay, num_epochs, patience, min_delta, Save=True, HistName='Hist', LearningName='Learning')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
